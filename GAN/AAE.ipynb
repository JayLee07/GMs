{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import itertools\n",
    "import imageio\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from dataset import get_data\n",
    "from scipy.misc import imsave\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as v_utils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'MNIST'\n",
    "        self.dataroot = '/data/jehyuk/imgdata'\n",
    "        self.workers = 2\n",
    "        self.n_gpu = 1\n",
    "        self.batchsize = 64\n",
    "        self.maxepoch = 100\n",
    "        self.imagesize = 64\n",
    "        self.lrG = 0.0002\n",
    "        self.lrD = 0.0002\n",
    "        self.channel_bunch = 64\n",
    "        self.use_cuda = True\n",
    "        self.n_z = 64\n",
    "        self.result_dir = '/home/jehyuk/GenerativeModels/GAN/results/AAE/' + self.dataset\n",
    "        self.save_dir = '/home/jehyuk/GenerativeModels/GAN/models/AAE/' + self.dataset\n",
    "        self.n_sample = 16\n",
    "\n",
    "opt = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(20)\n",
    "torch.cuda.manual_seed_all(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataroot = opt.dataroot, dataset=opt.dataset):\n",
    "    data_folder = os.path.join(dataroot, dataset)\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    transform = transforms.Compose([transforms.Scale(opt.imagesize),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "    if dataset == 'MNIST':\n",
    "        trn_data = dset.MNIST(data_folder, train=True, transform=transform, download=True)\n",
    "        tst_data = dset.MNIST(data_folder, train=False, transform=transform, download=True)\n",
    "        n_channels = 1\n",
    "    elif dataset == 'Fashion-MNIST':\n",
    "        trn_data = dset.FashionMNIST(data_folder, train=True, transform=transform, download=True)\n",
    "        tst_data = dset.FashionMNIST(data_folder, train=False, transform=transform, download=True)\n",
    "        n_channels = 1\n",
    "    elif dataset == 'CIFAR10':\n",
    "        trn_data = dset.cifar.CIFAR10(data_folder, train=True, transform=transform, download=True)\n",
    "        tst_data = dset.cifar.CIFAR10(data_folder, train=False, transform=transform, download=True)\n",
    "        n_channels = 3\n",
    "    elif dataset == 'CelebA':\n",
    "        trn_data = get_data(data_folder, split='train', image_size=opt.imagesize)\n",
    "        tst_data = get_data(data_folder, split='test', image_size=opt.imagesize)\n",
    "        n_channels = 3\n",
    "    trn_loader = utils.data.DataLoader(trn_data, batch_size=opt.batchsize, shuffle=True, num_workers=opt.workers, drop_last=True)\n",
    "    tst_loader = utils.data.DataLoader(tst_data, batch_size=opt.batchsize, shuffle=False, num_workers=opt.workers, drop_last=True)\n",
    "    return trn_loader, tst_loader, n_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('LInear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        layers = nn.Sequential()\n",
    "        layers.add_module(\"Linear1\", nn.Linear(self.config.imagesize*self.config.imagesize, 1000))\n",
    "        layers.add_module(\"Activation1\", nn.ReLU(inplace=True))\n",
    "        layers.add_module(\"Linear2\", nn.Linear(1000, 1000))\n",
    "        layers.add_module(\"Activation2\", nn.ReLU(inplace=True))\n",
    "        layers.add_module(\"Linear3\", nn.Linear(1000, self.config.n_z))\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.config.imagesize * self.config.imagesize)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        layers = nn.Sequential()\n",
    "        layers.add_module(\"Linear1\", nn.Linear(config.n_z, 1000))\n",
    "        layers.add_module(\"Activation1\", nn.ReLU(inplace=True))\n",
    "        layers.add_module(\"Linear2\", nn.Linear(1000, 1000))\n",
    "        layers.add_module(\"Activation2\", nn.ReLU(inplace=True))\n",
    "        layers.add_module(\"Linear3\", nn.Linear(1000, self.config.imagesize*self.config.imagesize))\n",
    "        layers.add_module(\"Activation3\", nn.Sigmoid())\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, z):\n",
    "        x = self.layers(z)\n",
    "        x = x.view(-1, self.config.imagesize, self.config.imagesize)\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        layers = nn.Sequential()\n",
    "        layers.add_module(\"Linear1\", nn.Linear(config.n_z, 1000))\n",
    "        layers.add_module(\"Activation1\", nn.ReLU(inplace=True))\n",
    "        layers.add_module(\"Linear2\", nn.Linear(1000, 1000))\n",
    "        layers.add_module(\"Activation2\", nn.ReLU(inplace=True))\n",
    "        layers.add_module(\"Linear3\", nn.Linear(1000, 1))\n",
    "        layers.add_module(\"Activation3\", nn.Sigmoid())\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.layers(z)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AAE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AAE, self).__init__()\n",
    "        self.config = config\n",
    "        self.trn_loader, self.tst_loader, _ = load_dataset(self.config.dataroot, self.config.dataset)\n",
    "        self.is_cuda = torch.cuda.is_available()\n",
    "        \n",
    "        self.encoder = Encoder(self.config)\n",
    "        self.decoder = Decoder(self.config)\n",
    "        self.discriminator = Discriminator(self.config)\n",
    "        self.encoder.apply(initialize_weights)\n",
    "        self.decoder.apply(initialize_weights)\n",
    "\n",
    "        self.discriminator.apply(initialize_weights)\n",
    "        self.sample_z = Variable(torch.randn((self.config.n_sample, self.config.n_z)), volatile=True)\n",
    "        \n",
    "        if self.is_cuda and self.config.use_cuda:\n",
    "            selfencoder, self.decoder, self.discriminator = self.encoder.cuda(), self.decoder.cuda(), self.discriminator.cuda()\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "        \n",
    "        self.optim_encoder = torch.optim.Adam(params=self.encoder.parameters(), lr=self.config.lrG, betas=(0.5, 0.999))\n",
    "        self.optim_decoder = torch.optim.Adam(params=self.decoder.parameters(), lr=self.config.lrG, betas=(0.5, 0.999))\n",
    "        self.optim_generator = torch.optim.Adam(params=self.encoder.parameters(), lr = self.config.lrG, betas=(0.5, 0.999))\n",
    "        self.optim_discriminator = torch.optim.Adam(params=self.discriminator.parameters(), lr=self.config.lrD, betas=(0.5, 0.999))\n",
    "        self.BCEloss = nn.BCELoss()\n",
    "        self.MSEloss = nn.MSELoss()\n",
    "        \n",
    "    def train(self):\n",
    "        self.loss_dict=dict()\n",
    "        self.loss_dict['recon_loss'] = list()\n",
    "        self.loss_dict['D_fake_loss'], self.loss_dict['D_real_loss'], self.loss_dict['D_loss'] = list(), list(), list()\n",
    "        \n",
    "        print('------------------Start training------------------')\n",
    "        for epoch in range(self.config.maxepoch):\n",
    "            print(\">>>>Epoch: {}\".format(epoch+1))\n",
    "            start_time = time.time()\n",
    "            for iter_num, (image, label) in enumerate(self.trn_loader):\n",
    "                # Train the autoencoder\n",
    "                self.encoder.train()\n",
    "                self.decoder.train()\n",
    "                \n",
    "                self.encoder.zero_grad()\n",
    "                self.decoder.zero_grad()\n",
    "                x = Variable(image)\n",
    "                if self.is_cuda:\n",
    "                    x = x.cuda()\n",
    "                x_recon = self.decoder.forward(self.encoder.forward(x))\n",
    "                recon_loss = self.MSEloss(x_recon, x)\n",
    "                recon_loss.backward()\n",
    "                self.optim_encoder.step()\n",
    "                self.optim_decoder.step()\n",
    "                \n",
    "                # Train the discriminator\n",
    "                self.discriminator.train()\n",
    "                self.encoder.eval()\n",
    "                fake_z, fake_z_label = self.encoder.forward(x), Variable(torch.zeros(self.config.batchsize, 1))\n",
    "                real_z, real_z_label = Variable(torch.randn(self.config.batch_size, self.n_z)), Variable(torch.ones(self.config.batchsize, 1))\n",
    "                if self.is_cuda:\n",
    "                    real_z = real_z.cuda()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "optimizer can only optimize Variables, but one of the params is tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d9b51f2732ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-1788a2befd9d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_AE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jehyuk/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay)\u001b[0m\n\u001b[1;32m     27\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     28\u001b[0m                         weight_decay=weight_decay)\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jehyuk/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jehyuk/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 raise TypeError(\"optimizer can only optimize Variables, \"\n\u001b[0;32m--> 151\u001b[0;31m                                 \"but one of the params is \" + torch.typename(param))\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizing a parameter that doesn't require gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: optimizer can only optimize Variables, but one of the params is tuple"
     ]
    }
   ],
   "source": [
    "aae = AAE(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
