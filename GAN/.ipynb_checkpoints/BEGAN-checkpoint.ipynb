{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import itertools\n",
    "import imageio\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from dataset import get_data\n",
    "from scipy.misc import imsave\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.utils as utils\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as v_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'CelebA'\n",
    "        self.dataroot = '/data/jehyuk/imgdata'\n",
    "        self.workers = 2\n",
    "        self.n_gpu = 1\n",
    "        self.batchsize = 16\n",
    "        self.maxepoch = 20\n",
    "        self.imagesize = 64\n",
    "        self.lrG = 2e-5\n",
    "        self.lrD = 2e-5\n",
    "        self.channel_bunch = 64\n",
    "        self.use_cuda = True\n",
    "        self.n_z = 64\n",
    "        self.result_dir = '/home/jehyuk/GenerativeModels/GAN/results/BEGAN/' + self.dataset\n",
    "        self.save_dir = '/home/jehyuk/GenerativeModels/GAN/models/BEGAN' + self.dataset\n",
    "        self.n_sample = 16\n",
    "\n",
    "opt = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataroot = opt.dataroot, dataset=opt.dataset):\n",
    "    data_folder = os.path.join(dataroot, dataset)\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    transform = transforms.Compose([transforms.Scale(opt.imagesize),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "    if dataset == 'MNIST':\n",
    "        trn_data = dset.MNIST(data_folder, train=True, transform=transform, download=True)\n",
    "        tst_data = dset.MNIST(data_folder, train=False, transform=transform, download=True)\n",
    "        n_channels = 1\n",
    "    elif dataset == 'Fashion-MNIST':\n",
    "        trn_data = dset.FashionMNIST(data_folder, train=True, transform=transform, download=True)\n",
    "        tst_data = dset.FashionMNIST(data_folder, train=False, transform=transform, download=True)\n",
    "        n_channels = 1\n",
    "    elif dataset == 'CIFAR10':\n",
    "        trn_data = dset.cifar.CIFAR10(data_folder, train=True, transform=transform, download=True)\n",
    "        tst_data = dset.cifar.CIFAR10(data_folder, train=False, transform=transform, download=True)\n",
    "        n_channels = 3\n",
    "    elif dataset == 'CelebA':\n",
    "        trn_data = get_data(data_folder, split='train', image_size=opt.imagesize)\n",
    "        tst_data = get_data(data_folder, split='test', image_size=opt.imagesize)\n",
    "        n_channels = 3\n",
    "    trn_loader = utils.data.DataLoader(trn_data, batch_size=opt.batchsize, shuffle=True, num_workers=opt.workers, drop_last=True)\n",
    "    tst_loader = utils.data.DataLoader(tst_data, batch_size=opt.batchsize, shuffle=False, num_workers=opt.workers, drop_last=True)\n",
    "    return trn_loader, tst_loader, n_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "#         m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    image = np.squeeze(merge(images, size))\n",
    "    return imsave(image_path, image)\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    if (images.shape[3] in (3,4)):\n",
    "        c = images.shape[3]\n",
    "        img = np.zeros((h * size[0], w * size[1], c))\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]\n",
    "            j = idx // size[1]\n",
    "            img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "        return img\n",
    "    elif images.shape[3]==1:\n",
    "        img = np.zeros((h * size[0], w * size[1]))\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]\n",
    "            j = idx // size[1]\n",
    "            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n",
    "        return img\n",
    "    else:\n",
    "        raise ValueError('in merge(images,size) images parameter ''must have dimensions: HxW or HxWx3 or HxWx4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, opt, n_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        self.linear_layers = nn.Linear(self.opt.n_z, 8*8*self.opt.channel_bunch)\n",
    "        \n",
    "        layers = nn.Sequential()\n",
    "        \n",
    "        layers.add_module(\"Conv1-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation1-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv1-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation1-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Upsampling1\", nn.Upsample(scale_factor=2))\n",
    "        \n",
    "        layers.add_module(\"Conv2-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation2-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv2-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation2-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Upsampling2\", nn.Upsample(scale_factor=2))\n",
    "        \n",
    "        layers.add_module(\"Conv3-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation3-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv3-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation3-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Upsampling3\", nn.Upsample(scale_factor=2))\n",
    "        \n",
    "        layers.add_module(\"Conv4-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation4-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv4-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation4-2\", nn.ELU(inplace=True))\n",
    "        \n",
    "        layers.add_module(\"Conv5\", nn.Conv2d(self.opt.channel_bunch, self.n_channels, kernel_size=3, stride=1, padding=1))\n",
    "#         layers.add_module(\"Activation4\", nn.Sigmoid())\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, z):\n",
    "        x = self.linear_layers(z)\n",
    "        x = x.view(-1, self.opt.channel_bunch, 8, 8)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, opt, n_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        self.linear_layers = nn.Linear(self.opt.n_z, 8*8*self.opt.channel_bunch)\n",
    "        \n",
    "        layers = nn.Sequential()\n",
    "        \n",
    "        layers.add_module(\"Conv1-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation1-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv1-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation1-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Upsampling1\", nn.Upsample(scale_factor=2))\n",
    "        \n",
    "        layers.add_module(\"Conv2-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation2-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv2-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation2-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Upsampling2\", nn.Upsample(scale_factor=2))\n",
    "        \n",
    "        layers.add_module(\"Conv3-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation3-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv3-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation3-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Upsampling3\", nn.Upsample(scale_factor=2))\n",
    "        \n",
    "        layers.add_module(\"Conv4-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation4-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv4-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation4-2\", nn.ELU(inplace=True))\n",
    "        \n",
    "        layers.add_module(\"Conv5\", nn.Conv2d(self.opt.channel_bunch, self.n_channels, kernel_size=3, stride=1, padding=1))\n",
    "#         layers.add_module(\"Activation4\", nn.Sigmoid())\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, z):\n",
    "        x = self.linear_layers(z)\n",
    "        x = x.view(-1, self.opt.channel_bunch, 8, 8)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, opt, n_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        layers = nn.Sequential()\n",
    "        layers.add_module(\"Conv0\", nn.Conv2d(self.n_channels, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        layers.add_module(\"Conv1-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation1-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv1-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation1-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Subsampling1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=2, padding=1))\n",
    "        layers.add_module(\"Activation1-3\", nn.ELU(inplace=True))\n",
    "        \n",
    "        layers.add_module(\"Conv2-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch*2, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation2-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv2-2\", nn.Conv2d(self.opt.channel_bunch*2, self.opt.channel_bunch*2, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation2-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Subsampling2\", nn.Conv2d(self.opt.channel_bunch*2, self.opt.channel_bunch*2, kernel_size=3, stride=2, padding=1))\n",
    "        layers.add_module(\"Activation2-3\", nn.ELU(inplace=True))\n",
    "        \n",
    "        layers.add_module(\"Conv3-1\", nn.Conv2d(self.opt.channel_bunch*2, self.opt.channel_bunch*3, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation3-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv3-2\", nn.Conv2d(self.opt.channel_bunch*3, self.opt.channel_bunch*3, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation3-2\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Subsampling3\", nn.Conv2d(self.opt.channel_bunch*3, self.opt.channel_bunch*3, kernel_size=3, stride=2, padding=1))\n",
    "        layers.add_module(\"Activation3-3\", nn.ELU(inplace=True))\n",
    "        \n",
    "        layers.add_module(\"Conv4-1\", nn.Conv2d(self.opt.channel_bunch*3, self.opt.channel_bunch*4, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation4-1\", nn.ELU(inplace=True))\n",
    "        layers.add_module(\"Conv4-2\", nn.Conv2d(self.opt.channel_bunch*4, self.opt.channel_bunch*4, kernel_size=3, stride=1, padding=1))\n",
    "        layers.add_module(\"Activation4-2\", nn.ELU(inplace=True))\n",
    "\n",
    "        self.layers = layers\n",
    "        self.linear_layers = nn.Linear(8*8*self.opt.channel_bunch*4, self.opt.n_z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(-1, 8*8*self.opt.channel_bunch*4)\n",
    "        z = self.linear_layers(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, opt, n_channels):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.opt = opt\n",
    "#         self.n_channels = n_channels\n",
    "        \n",
    "#         layers = nn.Sequential()\n",
    "#         layers.add_module(\"Conv0\", nn.Conv2d(self.n_channels, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "#         layers.add_module(\"Conv1-1\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch, kernel_size=3, stride=1, padding=1))\n",
    "#         layers.add_module(\"Activation1-1\", nn.ELU(inplace=True))\n",
    "#         layers.add_module(\"Conv1-2\", nn.Conv2d(self.opt.channel_bunch, self.opt.channel_bunch*2, kernel_size=3, stride=1, padding=1))\n",
    "#         layers.add_module(\"Activation1-2\", nn.ELU(inplace=True))\n",
    "#         layers.add_module(\"Subsampling1\", nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "#         layers.add_module(\"Conv2-1\", nn.Conv2d(self.opt.channel_bunch*2, self.opt.channel_bunch*2, kernel_size=3, stride=1, padding=1))\n",
    "#         layers.add_module(\"Activation2-1\", nn.ELU(inplace=True))\n",
    "#         layers.add_module(\"Conv2-2\", nn.Conv2d(self.opt.channel_bunch*2, self.opt.channel_bunch*3, kernel_size=3, stride=1, padding=1))\n",
    "#         layers.add_module(\"Activation2-2\", nn.ELU(inplace=True))\n",
    "#         layers.add_module(\"Subsampling2\", nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "#         layers.add_module(\"Conv3-1\", nn.Conv2d(self.opt.channel_bunch*3, self.opt.channel_bunch*3, kernel_size=3, stride=1, padding=1))\n",
    "#         layers.add_module(\"Activation3-1\", nn.ELU(inplace=True))\n",
    "#         layers.add_module(\"Conv3-2\", nn.Conv2d(self.opt.channel_bunch*3, self.opt.channel_bunch*3, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "#         self.layers = layers\n",
    "#         self.linear_layers = nn.Linear(8*8*self.opt.channel_bunch*3, self.opt.n_z)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.layers(x)\n",
    "#         x = x.view(-1, 8*8*self.opt.channel_bunch*3)\n",
    "#         z = self.linear_layers(x)\n",
    "#         return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, opt, n_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.encoder = Encoder(opt, n_channels)\n",
    "        self.decoder = Decoder(opt, n_channels)\n",
    "    def forward(self, x):\n",
    "        z = self.encoder.forward(x)\n",
    "        x_hat = self.decoder.forward(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BEGAN(object):\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        self.trn_loader, self.tst_loader, self.n_channels = load_dataset(self.opt.dataroot, self.opt.dataset)\n",
    "        self.is_cuda = torch.cuda.is_available()\n",
    "        self.gamma = 0.75\n",
    "        self.lambda_ = 0.001\n",
    "        self.k = 0.0\n",
    "        \n",
    "        self.G = Generator(self.opt, self.n_channels)\n",
    "        self.D = Discriminator(self.opt, self.n_channels)\n",
    "        self.G.apply(initialize_weights)\n",
    "        self.D.apply(initialize_weights)\n",
    "        self.sample_z = Variable(torch.rand((self.opt.n_sample, self.opt.n_z)), volatile=True)\n",
    "                \n",
    "        if self.is_cuda and self.opt.use_cuda:\n",
    "            self.G, self.D = self.G.cuda(), self.D.cuda()\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "        \n",
    "        self.optim_G = torch.optim.Adam(self.G.parameters(), lr = self.opt.lrG, betas=(0.5,0.999))\n",
    "        self.optim_D = torch.optim.Adam(self.D.parameters(), lr = self.opt.lrD, betas=(0.5,0.999))\n",
    "        \n",
    "    def train(self):\n",
    "        self.loss_dict=dict()\n",
    "        self.loss_dict['G_loss'], self.loss_dict['D_loss'] = list(), list()\n",
    "        self.loss_dict['conv_measure'] = list()\n",
    "        \n",
    "        \n",
    "        self.D.train()\n",
    "        print('------------------Start training------------------')\n",
    "        for epoch in range(self.opt.maxepoch):\n",
    "            self.G.train()\n",
    "            print(\">>>>Epoch: {}\".format(epoch+1))\n",
    "            start_time = time.time()\n",
    "            for iter_num, (image, label) in enumerate(self.trn_loader):\n",
    "                x = Variable(image)\n",
    "                z1 = Variable(torch.randn(self.opt.batchsize, self.opt.n_z))\n",
    "                z2 = Variable(torch.randn(self.opt.batchsize, self.opt.n_z))\n",
    "                if self.is_cuda:\n",
    "                    x, z1, z2 = x.cuda(), z1.cuda(), z2.cuda()\n",
    "                \n",
    "                # Train D\n",
    "                self.D.zero_grad()\n",
    "                D_x = self.D.forward(x)\n",
    "                L_x = torch.mean(torch.abs(x - D_x))\n",
    "                \n",
    "                G_z = self.G.forward(z1)\n",
    "                D_G_z = self.D.forward(G_z)\n",
    "                L_Gz = torch.mean(torch.abs(G_z - D_G_z))\n",
    "                \n",
    "                D_loss = L_x - self.k * L_Gz\n",
    "                self.loss_dict['D_loss'].append(D_loss.data[0])\n",
    "                D_loss.backward()\n",
    "                self.optim_D.step()\n",
    "                \n",
    "                #Train G\n",
    "                self.G.zero_grad()\n",
    "                G_z = self.G.forward(z2)\n",
    "                D_G_z = self.D.forward(G_z)\n",
    "                L_Gz = torch.mean(torch.abs(G_z - D_G_z))\n",
    "                G_loss = L_Gz\n",
    "                \n",
    "                self.loss_dict['G_loss'].append(G_loss.data[0])\n",
    "                G_loss.backward()\n",
    "                self.optim_G.step()\n",
    "                \n",
    "                #Convergence Metric(M)\n",
    "                M = L_x + torch.abs(self.gamma * L_x - L_Gz)\n",
    "                \n",
    "                # Update k\n",
    "                tmp_k = self.k + self.lambda_ * (self.gamma*L_x - L_Gz)\n",
    "                tmp_k = tmp_k.data[0]\n",
    "                \n",
    "                self.k = min(max(tmp_k, 0), 1) # To make 0<=k<=1\n",
    "                self.M = M.data[0]\n",
    "                self.loss_dict['conv_measure'].append(M.data[0])\n",
    "\n",
    "                if (iter_num+1) % 500 == 0:\n",
    "                    print(\"Epoch: {}, iter: {}, D_loss: {:.3f}, G_loss: {:.3f}, M: {:.3f}\".format(epoch+1, iter_num+1, D_loss.data[0], G_loss.data[0], M.data[0]))\n",
    "            print(\">>>>Time for 1 epoch: {:.2f}\".format(time.time()-start_time))\n",
    "            self.save_results(epoch+1, self.sample_z)\n",
    "        self.save_model()\n",
    "            \n",
    "    def save_results(self, epoch, sample):\n",
    "        self.G.eval()\n",
    "        if not os.path.exists(self.opt.result_dir):\n",
    "            os.makedirs(self.opt.result_dir)\n",
    "        fake_file_name = self.opt.result_dir + '/BEGAN_epoch%03d' %epoch + '.png'\n",
    "        fake_results = self.G.forward(sample)\n",
    "        v_utils.save_image(fake_results.data, fake_file_name, nrow = int(math.sqrt(self.opt.n_sample)), normalize=True)\n",
    "    \n",
    "#     def visualize_results(self, epoch, _iter, fix=True):\n",
    "#         self.G.eval()\n",
    "#         if not os.path.exists(self.opt.result_dir):\n",
    "#             os.makedirs(self.opt.result_dir)\n",
    "#         image_frame_dim = int(np.floor(np.sqrt(self.opt.n_sample)))\n",
    "        \n",
    "#         if fix:\n",
    "#             G_z_sample = self.G(self.sample_z)\n",
    "#         else:\n",
    "#             sample_z = Variable(torch.randn((self.opt.n_sample, self.opt.n_z)), volatile=True)\n",
    "#             if self.is_cuda and self.opt.use_cuda:\n",
    "#                 sample_z = sample_z.cuda()\n",
    "#             G_z_sample = self.G(sample_z)\n",
    "\n",
    "#         if self.is_cuda and self.opt.use_cuda:\n",
    "#             G_z_sample = G_z_sample.cpu().data.numpy().transpose(0,2,3,1)\n",
    "#         else:\n",
    "#             G_z_sample = G_z_sample.data.numpy().transpose(0,2,3,1)\n",
    "\n",
    "#         save_images(G_z_sample[:image_frame_dim * image_frame_dim,:,:,:], [image_frame_dim, image_frame_dim], self.opt.result_dir + '/' + 'BEGAN_epoch%03d_iter%04d' %(epoch, _iter)  + '.png')\n",
    "        \n",
    "    def save_model(self):\n",
    "        if not os.path.exists(self.opt.save_dir):\n",
    "            os.makedirs(self.opt.save_dir)\n",
    "        torch.save(self.G.state_dict(), os.path.join(self.opt.save_dir, 'G.pkl'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(self.opt.save_dir, 'D.pkl'))\n",
    "        with open(os.path.join(self.opt.save_dir, 'loss_dict'), 'wb') as f:\n",
    "            pickle.dump(self.loss_dict, f)\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.G.load_state_dict(torch.load(os.path.join(self.opt.save_dir, 'G.pkl')))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(self.opt.save_dir, 'D.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 162770 images in subfolders of: /data/jehyuk/imgdata/CelebA/splits/train\n",
      "Found 19962 images in subfolders of: /data/jehyuk/imgdata/CelebA/splits/test\n",
      "------------------Start training------------------\n",
      ">>>>Epoch: 1\n",
      "Epoch: 1, iter: 500, D_loss: 0.127, G_loss: 0.074, M: 0.151\n",
      "Epoch: 1, iter: 1000, D_loss: 0.116, G_loss: 0.069, M: 0.139\n",
      "Epoch: 1, iter: 1500, D_loss: 0.104, G_loss: 0.055, M: 0.133\n",
      "Epoch: 1, iter: 2000, D_loss: 0.107, G_loss: 0.053, M: 0.140\n",
      "Epoch: 1, iter: 2500, D_loss: 0.101, G_loss: 0.054, M: 0.131\n",
      "Epoch: 1, iter: 3000, D_loss: 0.093, G_loss: 0.054, M: 0.117\n",
      "Epoch: 1, iter: 3500, D_loss: 0.098, G_loss: 0.049, M: 0.130\n"
     ]
    }
   ],
   "source": [
    "began = BEGAN(opt)\n",
    "began.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"/home/jehyuk/GenerativeModels/GAN/results/BEGAN/CelebA/BEGAN_epoch004_iter3000.png\", width = 256, height=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"/home/jehyuk/GenerativeModels/GAN/results/BEGAN/CelebA/BEGAN_epoch008_iter3000.png\", width = 256, height=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"/home/jehyuk/GenerativeModels/GAN/results/BEGAN/CelebA/BEGAN_epoch012_iter3000.png\", width = 256, height=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"/home/jehyuk/GenerativeModels/GAN/results/BEGAN/CelebA/BEGAN_epoch016_iter3000.png\", width = 256, height=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"/home/jehyuk/GenerativeModels/GAN/results/BEGAN/CelebA/BEGAN_epoch020_iter3000.png\", width = 256, height=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
